{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e866ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"=\"*80)\n",
    "print(\"EXECUCI√ì COMPLETA DEL NOTEBOOK - AN√ÄLISI DE MODELS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdaa46",
   "metadata": {},
   "source": [
    "# Selecci√≥ de Models\n",
    "En la Demo1 nom√©s este en compte la filtraci√≥ de dades (Tractaments de valors faltants) i eliminaci√≥ de columnes que no tenen correlaci√≥ amb el **target = winner**.\n",
    "\n",
    "- **Model 1:** Elimaci√≥ de les columnes de la correlaci√≥\n",
    "- **Model 2:** + Elimaci√≥ de les columnes que determinen quin heroi a acabat amb una estructura\n",
    "- **Model 3:** + Eliminaci√≥ dels *first*\n",
    "\n",
    "\n",
    "**NOTA:** Algunes de les funcions utilitzades estan en el document **funcions.py** per millorar al visualitzaci√≥ del NoteBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer de tot carreguem les llibreries necess√†ries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "from funcions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressi√≥ log√≠stica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "# XGBoost\n",
    "#from xgboost import XGBClassifier\n",
    "# LightGBM\n",
    "#from lightgbm import LGBMClassifier\n",
    "# CatBoost\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea768b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = pd.read_csv('../../LOL - Dataset/games.csv')\n",
    "\n",
    "print(\"üìä RESUM DE LES DADES ORIGINALS:\")\n",
    "print(f\"Files: {DataSet.shape[0]}, Columnes: {DataSet.shape[1]}\")\n",
    "print(f\"\\nValors NaN totals: {DataSet.isna().sum().sum()}\")\n",
    "print(f\"Files amb NaN: {DataSet.isna().any(axis=1).sum()}\")\n",
    "\n",
    "# Eliminar duplicats\n",
    "duplicated_rows = DataSet[DataSet.duplicated(keep=False)]\n",
    "print(f\"\\nüìã Nombre de files duplicades: {len(duplicated_rows)} de {len(DataSet)}\")\n",
    "DataSet_cleaned = DataSet.drop_duplicates()\n",
    "print(f\"‚úÖ Files despr√©s d'eliminar duplicats: {len(DataSet_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470df4b0",
   "metadata": {},
   "source": [
    "Com hem determinat al final del document de **Correlaci√≥**, eliminarem els atributs que no tenen correlaci√≥ directa amb el target **winner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd270159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaci√≥ columnes determinades per la primera correlaci√≥\n",
    "cols_to_remove = [f't{team}_champ{i}id' for team in [1, 2] for i in range(1, 6)]\n",
    "cols_to_remove += [f't{team}_champ{champ}_sum{s}' for team in [1, 2] for champ in range(1, 6) for s in [1,2]]\n",
    "cols_to_remove += [f't{team}_ban{champ}' for team in [1, 2] for champ in range(1, 6)]\n",
    "\n",
    "\n",
    "# Eliminaci√≥ de columnes que determinen quins herois de cada equip a acabat amb una estructura\n",
    "cols_to_remove  += ['t1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills',\n",
    "                    't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills']\n",
    "\n",
    "\n",
    "# Verificar quines columnes existeixen\n",
    "existing_cols = [col for col in cols_to_remove if col in DataSet_cleaned.columns]\n",
    "DataSet_cleaned = DataSet_cleaned.drop(columns=existing_cols, errors='ignore')\n",
    "print(f\"Columnes restants: {DataSet_cleaned.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c21dc",
   "metadata": {},
   "source": [
    "## Preparaci√≥ de les dades d'entrenament i predicci√≥\n",
    "A continuaci√≥ farem la validaci√≥ creuada i la selecci√≥ dels hiperpar√†metres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Separa les dades en train, validation i test\n",
    "    \"\"\"\n",
    "    # Primer separaci√≥: train+val (80%) i test (20%)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Segona separaci√≥: train (60%) i val (20%)\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_relative_size, \n",
    "        random_state=random_state, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    print(f\"Train shape: {X_train.shape}\")\n",
    "    print(f\"Validation shape: {X_val.shape}\")\n",
    "    print(f\"Test shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def scale_data(X_train, X_val, X_test, method='standard'):\n",
    "    \"\"\"\n",
    "    Normalitza/estandarditza les dades\n",
    "    \"\"\"\n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"M√®tode ha de ser 'standard' o 'minmax'\")\n",
    "    \n",
    "    # Entrenar el scaler nom√©s amb les dades d'entrenament\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f290d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataSet_cleaned.drop('winner', axis=1)\n",
    "y = DataSet_cleaned['winner']\n",
    "\n",
    "print(f\"\\nüéØ DATES PER A MODELACI√ì:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nDistribuci√≥ de la variable objectiu:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "y = y.map({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a91c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar dades\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEPARANT LES DADES (Train/Val/Test)\")\n",
    "print(f\"{'='*60}\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    X, y, test_size=0.2, val_size=0.2\n",
    ")\n",
    "\n",
    "# Escalar dades\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"NORMALITZANT LES DADES\")\n",
    "print(f\"{'='*60}\")\n",
    "X_train_scaled, X_val_scaled, X_test_scaled, scaler = scale_data(\n",
    "    X_train, X_val, X_test, method='standard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Regressi√≥ Log√≠stica\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL 1: REGRESSI√ì LOG√çSTICA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Validaci√≥ creuada\n",
    "lr_base = LogisticRegression(max_iter=2000, random_state=42)\n",
    "cv_scores_lr = cross_validation_analysis(lr_base, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# Ajust d'hiperpar√†metres\n",
    "param_grids = get_param_grids()\n",
    "lr_best, lr_params, lr_search = hyperparameter_tuning(\n",
    "    lr_base, \n",
    "    param_grids['logistic'], \n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    method='random'\n",
    ")\n",
    "\n",
    "# Avaluaci√≥\n",
    "lr_metrics, lr_cm = evaluate_model(lr_best, X_val_scaled, y_val, \"Regressi√≥ Log√≠stica (Val)\")\n",
    "\n",
    "# Guardar resultats\n",
    "results = {}\n",
    "results['Logistic Regression'] = {\n",
    "    'model': lr_best,\n",
    "    'params': lr_params,\n",
    "    'cv_score': cv_scores_lr.mean(),\n",
    "    'val_metrics': lr_metrics\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01351c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 8: Model 2 - Random Forest\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Validaci√≥ creuada\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "cv_scores_rf = cross_validation_analysis(rf_base, X_train, y_train, cv=5)\n",
    "\n",
    "# Ajust d'hiperpar√†metres\n",
    "rf_best, rf_params, rf_search = hyperparameter_tuning(\n",
    "    rf_base, \n",
    "    param_grids['random_forest'], \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    method='random'\n",
    ")\n",
    "\n",
    "# Avaluaci√≥\n",
    "rf_metrics, rf_cm = evaluate_model(rf_best, X_val, y_val, \"Random Forest (Val)\")\n",
    "\n",
    "# Guardar resultats\n",
    "results['Random Forest'] = {\n",
    "    'model': rf_best,\n",
    "    'params': rf_params,\n",
    "    'cv_score': cv_scores_rf.mean(),\n",
    "    'val_metrics': rf_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 9: Model 3 - Gradient Boosting\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL 3: GRADIENT BOOSTING\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Validaci√≥ creuada\n",
    "gb_base = GradientBoostingClassifier(random_state=42)\n",
    "cv_scores_gb = cross_validation_analysis(gb_base, X_train, y_train, cv=5)\n",
    "\n",
    "# Ajust d'hiperpar√†metres\n",
    "gb_best, gb_params, gb_search = hyperparameter_tuning(\n",
    "    gb_base, \n",
    "    param_grids['gradient_boosting'], \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    method='random'\n",
    ")\n",
    "\n",
    "# Avaluaci√≥\n",
    "gb_metrics, gb_cm = evaluate_model(gb_best, X_val, y_val, \"Gradient Boosting (Val)\")\n",
    "\n",
    "# Guardar resultats\n",
    "results['Gradient Boosting'] = {\n",
    "    'model': gb_best,\n",
    "    'params': gb_params,\n",
    "    'cv_score': cv_scores_gb.mean(),\n",
    "    'val_metrics': gb_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f317f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 10: Model 4 - SVM (necessita scaling)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL 4: SVM\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Validaci√≥ creuada\n",
    "svm_base = SVC(probability=True, random_state=42)\n",
    "cv_scores_svm = cross_validation_analysis(svm_base, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# Ajust d'hiperpar√†metres (versi√≥ simplificada i m√©s r√†pida)\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_best, svm_params, svm_search = hyperparameter_tuning(\n",
    "    svm_base, \n",
    "    svm_param_grid, \n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    cv=3,  # Reducit a 3 folds per velocitat\n",
    "    method='random'\n",
    ")\n",
    "\n",
    "# Avaluaci√≥\n",
    "svm_metrics, svm_cm = evaluate_model(svm_best, X_val_scaled, y_val, \"SVM (Val)\")\n",
    "\n",
    "# Guardar resultats\n",
    "results['SVM'] = {\n",
    "    'model': svm_best,\n",
    "    'params': svm_params,\n",
    "    'cv_score': cv_scores_svm.mean(),\n",
    "    'val_metrics': svm_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 11: COMPARACI√ì DE TOTS ELS MODELS\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COMPARACI√ì DE TOTS ELS MODELS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Crear dataframe comparatiu\n",
    "comparison_data = []\n",
    "for model_name, model_info in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'CV Score': model_info['cv_score'],\n",
    "        'Val Accuracy': model_info['val_metrics']['Accuracy'],\n",
    "        'Val Precision': model_info['val_metrics']['Precision'],\n",
    "        'Val Recall': model_info['val_metrics']['Recall'],\n",
    "        'Val F1-Score': model_info['val_metrics']['F1-Score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìä TAULA DE COMPARACI√ì:\")\n",
    "print(comparison_df.sort_values('Val Accuracy', ascending=False))\n",
    "\n",
    "# Gr√†fic de comparaci√≥\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Accuracy comparatiu\n",
    "plt.subplot(2, 3, 1)\n",
    "sorted_df = comparison_df.sort_values('Val Accuracy', ascending=True)\n",
    "plt.barh(sorted_df['Model'], sorted_df['Val Accuracy'], color='skyblue')\n",
    "plt.title('Accuracy (Validation)')\n",
    "plt.xlabel('Accuracy')\n",
    "\n",
    "# CV Score comparatiu\n",
    "plt.subplot(2, 3, 2)\n",
    "sorted_df = comparison_df.sort_values('CV Score', ascending=True)\n",
    "plt.barh(sorted_df['Model'], sorted_df['CV Score'], color='lightgreen')\n",
    "plt.title('Cross-Validation Score')\n",
    "plt.xlabel('CV Score')\n",
    "\n",
    "# F1-Score comparatiu\n",
    "plt.subplot(2, 3, 3)\n",
    "sorted_df = comparison_df.sort_values('Val F1-Score', ascending=True)\n",
    "plt.barh(sorted_df['Model'], sorted_df['Val F1-Score'], color='lightcoral')\n",
    "plt.title('F1-Score (Validation)')\n",
    "plt.xlabel('F1-Score')\n",
    "\n",
    "# Matriu de correlaci√≥ de m√®triques\n",
    "plt.subplot(2, 3, 4)\n",
    "metrics_corr = comparison_df[['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1-Score', 'CV Score']].corr()\n",
    "sns.heatmap(metrics_corr, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Correlaci√≥ entre M√®triques')\n",
    "\n",
    "# Scatter plot: CV Score vs Val Accuracy\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(comparison_df['CV Score'], comparison_df['Val Accuracy'], s=100, alpha=0.7)\n",
    "for i, row in comparison_df.iterrows():\n",
    "    plt.annotate(row['Model'], (row['CV Score'], row['Val Accuracy']), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('CV Score vs Validation Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Ranking global\n",
    "plt.subplot(2, 3, 6)\n",
    "# Crear score combinat (mitjana de totes les m√®triques)\n",
    "comparison_df['Combined Score'] = comparison_df[['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1-Score', 'CV Score']].mean(axis=1)\n",
    "sorted_df = comparison_df.sort_values('Combined Score', ascending=True)\n",
    "plt.barh(sorted_df['Model'], sorted_df['Combined Score'], color='gold')\n",
    "plt.title('Ranking Global (Mitjana de totes les m√®triques)')\n",
    "plt.xlabel('Score Combinat')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 12: SELECCI√ì DEL MILLOR MODEL I AVALUACI√ì FINAL\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SELECCI√ì DEL MILLOR MODEL\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Seleccionar el millor model basat en accuracy de validaci√≥\n",
    "best_model_name = comparison_df.loc[comparison_df['Val Accuracy'].idxmax(), 'Model']\n",
    "best_model_info = results[best_model_name]\n",
    "best_model = best_model_info['model']\n",
    "\n",
    "print(f\"üéØ MILLOR MODEL SELECCIONAT: {best_model_name}\")\n",
    "print(f\"üìä Par√†metres: {best_model_info['params']}\")\n",
    "print(f\"üèÜ Validation Accuracy: {best_model_info['val_metrics']['Accuracy']:.4f}\")\n",
    "\n",
    "# Determinar si cal escalar les dades per al millor model\n",
    "needs_scaling = best_model_name in ['Logistic Regression', 'SVM']\n",
    "X_test_to_use = X_test_scaled if needs_scaling else X_test\n",
    "\n",
    "# AVALUACI√ì FINAL AMB TEST SET\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AVALUACI√ì FINAL AMB TEST SET\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Avaluar el millor model amb el test set\n",
    "test_metrics, test_cm = evaluate_model(best_model, X_test_to_use, y_test, \n",
    "                                       f\"{best_model_name} (Test Final)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b429404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√®l¬∑lula 13: RESUM FINAL I CONCLUSIONS\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESUM FINAL I CONCLUSIONS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE FINAL DEL MILLOR MODEL ({best_model_name}):\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {test_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test Precision: {test_metrics['Precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test Recall: {test_metrics['Recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test F1-Score: {test_metrics['F1-Score']:.4f}\")\n",
    "if 'ROC-AUC' in test_metrics:\n",
    "    print(f\"   ‚Ä¢ Test ROC-AUC: {test_metrics['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  HIPERPAR√ÄMETRES OPTIMITZATS:\")\n",
    "for param, value in best_model_info['params'].items():\n",
    "    print(f\"   ‚Ä¢ {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä COMPARACI√ì VALIDACI√ì vs TEST:\")\n",
    "print(f\"   ‚Ä¢ Validation Accuracy: {best_model_info['val_metrics']['Accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {test_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Difer√®ncia: {abs(best_model_info['val_metrics']['Accuracy'] - test_metrics['Accuracy']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGN√íSTIC DEL PROBLEMA\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DIAGN√íSTIC: VERIFICANT PROBLEMES COMUNS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 1. Verificar si hi ha data leakage\n",
    "print(\"\\nüîç 1. BUSCANT DATA LEAKAGE...\")\n",
    "\n",
    "# a) Comprovar correlacions amb winner\n",
    "print(\"\\na) Top 10 correlacions amb 'winner':\")\n",
    "# Primer, crea una c√≤pia temporal amb winner per calcular correlacions\n",
    "temp_df = DataSet_cleaned.copy()\n",
    "corr_with_target = temp_df.corr()['winner'].abs().sort_values(ascending=False)\n",
    "print(corr_with_target.head(10))\n",
    "\n",
    "# b) Buscar columnes que podrien contenir el resultat\n",
    "print(\"\\nb) Columnes que podrien contenir informaci√≥ del resultat:\")\n",
    "keywords = ['win', 'kill', 'death', 'gold', 'tower', 'inhib', 'dragon', 'baron', 'herald']\n",
    "for col in X.columns:\n",
    "    col_lower = col.lower()\n",
    "    for keyword in keywords:\n",
    "        if keyword in col_lower:\n",
    "            print(f\"   - {col}\")\n",
    "            break\n",
    "\n",
    "# 2. Model de l√≠nia base (baseline)\n",
    "print(\"\\nüîç 2. MODEL DE L√çNIA BASE (BASELINE):\")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Estrat√®gia: predir la classe m√©s freq√ºent\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(X_train_scaled, y_train)\n",
    "y_dummy_pred = dummy.predict(X_val_scaled)\n",
    "dummy_acc = accuracy_score(y_val, y_dummy_pred)\n",
    "\n",
    "print(f\"   Accuracy del DummyClassifier: {dummy_acc:.4f}\")\n",
    "print(f\"   Si el teu model ({best_model_name}) dona {best_model_info['val_metrics']['Accuracy']:.4f},\")\n",
    "print(f\"   est√† millorant en {best_model_info['val_metrics']['Accuracy'] - dummy_acc:.4f}\")\n",
    "\n",
    "# 3. An√†lisi de les dades\n",
    "print(\"\\nüîç 3. AN√ÄLISI DE LES DADES:\")\n",
    "print(f\"   Nombre total de mostres: {len(X)}\")\n",
    "print(f\"   Nombre de caracter√≠stiques: {len(X.columns)}\")\n",
    "\n",
    "# 4. Distribuci√≥ de probabilitats (si el model les d√≥na)\n",
    "if hasattr(best_model, 'predict_proba'):\n",
    "    print(\"\\nüîç 4. DISTRIBUCI√ì DE PROBABILITATS:\")\n",
    "    y_proba = best_model.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(y_proba[y_val == 0], bins=30, alpha=0.7, label='Team 1 (0)', color='blue')\n",
    "    plt.hist(y_proba[y_val == 1], bins=30, alpha=0.7, label='Team 2 (1)', color='red')\n",
    "    plt.xlabel('Probabilitat de guanyar Team 2')\n",
    "    plt.ylabel('Freq√º√®ncia')\n",
    "    plt.title('Distribuci√≥ de Probabilitats Predites')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Crear histograma de confian√ßa\n",
    "    confidence = np.where(y_proba > 0.5, y_proba, 1 - y_proba)\n",
    "    plt.hist(confidence, bins=30, alpha=0.7, color='green')\n",
    "    plt.xlabel('Confian√ßa de la predicci√≥ (m√†x(p, 1-p))')\n",
    "    plt.ylabel('Freq√º√®ncia')\n",
    "    plt.title('Distribuci√≥ de la Confian√ßa')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"   Mitjana de confian√ßa: {confidence.mean():.4f}\")\n",
    "    print(f\"   % prediccions amb confian√ßa > 0.9: {(confidence > 0.9).mean()*100:.1f}%\")\n",
    "\n",
    "# 5. Prova amb un subconjunt de dades (learning curve simple)\n",
    "print(\"\\nüîç 5. PROVA AMB MENYS DADES:\")\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_model, X_train_scaled, y_train,\n",
    "    cv=3, scoring='accuracy', n_jobs=-1,\n",
    "    train_sizes=[0.1, 0.3, 0.5, 0.7, 1.0]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', label='Train')\n",
    "plt.plot(train_sizes, val_scores.mean(axis=1), 'o-', label='Validation')\n",
    "plt.fill_between(train_sizes, \n",
    "                 train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                 train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                 alpha=0.1)\n",
    "plt.fill_between(train_sizes,\n",
    "                 val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                 val_scores.mean(axis=1) + val_scores.std(axis=1),\n",
    "                 alpha=0.1)\n",
    "plt.xlabel('Nombre de mostres d\\'entrenament')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Corba d\\'Aprenentatge')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Verificar si el problema √©s trivial\n",
    "print(\"\\nüîç 6. VERIFICANT SI EL PROBLEMA √âS TRIVIAL...\")\n",
    "\n",
    "# Comptar quantes files tenen el mateix patr√≥ per ambd√≥s equips\n",
    "# (aix√≤ podria indicar que alguna variable ho determina directament)\n",
    "\n",
    "# Exemple: si hi ha una columna que √©s 1 per guanyador, 0 per perdedor\n",
    "for col in X.columns:\n",
    "    unique_vals = X[col].unique()\n",
    "    if len(unique_vals) == 2 and set(unique_vals) == {0, 1}:\n",
    "        # Verificar correlaci√≥ perfecta\n",
    "        correlation = np.corrcoef(X[col], y)[0, 1]\n",
    "        if abs(correlation) > 0.95:\n",
    "            print(f\"   ALERTA: La columna '{col}' t√© correlaci√≥ {correlation:.4f} amb 'winner'!\")\n",
    "            print(f\"   Valors: {X[col].unique()}\")\n",
    "            print(f\"   Potser √©s el resultat mateix disfressat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DIAGN√íSTIC EXHAUSTIU - DETECCI√ì DE DATA LEAKAGE\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üîç DIAGN√íSTIC EXHAUSTIU: DETECCI√ì DE DATA LEAKAGE\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# 1. CORRELACIONS SOSPITOSES\n",
    "print(\"\\n1Ô∏è‚É£  TOP 30 CORRELACIONS AMB 'WINNER':\")\n",
    "print(\"=\"*60)\n",
    "temp_df = DataSet_cleaned.copy()\n",
    "corr_with_target = temp_df.corr()['winner'].abs().sort_values(ascending=False)\n",
    "print(corr_with_target.head(30))\n",
    "\n",
    "# 2. AN√ÅLISIS DE COLUMNAS PROBLEM√ÅTICAS\n",
    "print(\"\\n2Ô∏è‚É£  COLUMNES AMB CORRELACI√ì > 0.5:\")\n",
    "print(\"=\"*60)\n",
    "high_corr = corr_with_target[corr_with_target > 0.5]\n",
    "print(f\"Total: {len(high_corr)} columnes\")\n",
    "for col, corr_val in high_corr.items():\n",
    "    if col != 'winner':\n",
    "        print(f\"   ‚Ä¢ {col}: {corr_val:.4f}\")\n",
    "\n",
    "# 3. BASELINE COMPARISON\n",
    "print(\"\\n3Ô∏è‚É£  BASELINE (DUMMY CLASSIFIER):\")\n",
    "print(\"=\"*60)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dummy_most_freq = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy_most_freq.fit(X_train_scaled, y_train)\n",
    "baseline_acc = dummy_most_freq.score(X_val_scaled, y_val)\n",
    "\n",
    "print(f\"   Dummy (most_frequent) Accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"   {best_model_name} Accuracy: {best_model_info['val_metrics']['Accuracy']:.4f}\")\n",
    "print(f\"   Mejora: {best_model_info['val_metrics']['Accuracy'] - baseline_acc:.4f}\")\n",
    "\n",
    "if best_model_info['val_metrics']['Accuracy'] - baseline_acc < 0.05:\n",
    "    print(\"   ‚ö†Ô∏è  ALERTA: Mejora muy peque√±a respecto a baseline!\")\n",
    "\n",
    "# 4. AN√ÅLISIS DE DISTRIBUCION DE DATOS\n",
    "print(\"\\n4Ô∏è‚É£  AN√ÅLISIS DE DISTRIBUCI√ìN DE DATOS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   ‚Ä¢ Total muestras: {len(X)}\")\n",
    "print(f\"   ‚Ä¢ Total features: {len(X.columns)}\")\n",
    "print(f\"   ‚Ä¢ Distribuci√≥n target: {dict(y.value_counts())}\")\n",
    "print(f\"   ‚Ä¢ % Train: {len(X_train)/len(X)*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ % Val: {len(X_val)/len(X)*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ % Test: {len(X_test)/len(X)*100:.1f}%\")\n",
    "\n",
    "# 5. PROBABILIDADES PREDICHAS\n",
    "print(\"\\n5Ô∏è‚É£  DISTRIBUCI√ìN DE PROBABILIDADES:\")\n",
    "print(\"=\"*60)\n",
    "if hasattr(best_model, 'predict_proba'):\n",
    "    y_proba_val = best_model.predict_proba(X_val_scaled)[:, 1]\n",
    "    confidence = np.where(y_proba_val > 0.5, y_proba_val, 1 - y_proba_val)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Confianza media: {confidence.mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Confianza m√≠n/m√°x: {confidence.min():.4f} / {confidence.max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ % predicciones > 0.9 confianza: {(confidence > 0.9).mean()*100:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ % predicciones > 0.95 confianza: {(confidence > 0.95).mean()*100:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ % predicciones > 0.99 confianza: {(confidence > 0.99).mean()*100:.1f}%\")\n",
    "    \n",
    "    if (confidence > 0.95).mean() > 0.7:\n",
    "        print(\"   ‚ö†Ô∏è  ALERTA: ¬°Demasiadas predicciones con confianza muy alta!\")\n",
    "        print(\"   Posible DATA LEAKAGE detectado.\")\n",
    "\n",
    "# 6. COMPARACI√ìN VALIDACI√ìN vs TEST\n",
    "print(\"\\n6Ô∏è‚É£  COMPARACI√ìN VALIDACI√ìN vs TEST:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   ‚Ä¢ Val Accuracy: {best_model_info['val_metrics']['Accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {test_metrics['Accuracy']:.4f}\")\n",
    "diff = abs(best_model_info['val_metrics']['Accuracy'] - test_metrics['Accuracy'])\n",
    "print(f\"   ‚Ä¢ Diferencia: {diff:.4f}\")\n",
    "\n",
    "if diff > 0.1:\n",
    "    print(\"   ‚ö†Ô∏è  ALERTA: ¬°Gran diferencia entre validaci√≥n y test!\")\n",
    "    print(\"   Posible OVERFITTING o DATA LEAKAGE.\")\n",
    "\n",
    "# 7. COLUMNAS SOSPECHOSAS\n",
    "print(\"\\n7Ô∏è‚É£  B√öSQUEDA DE COLUMNAS SOSPECHOSAS:\")\n",
    "print(\"=\"*60)\n",
    "keywords = ['win', 'result', 'outcome', 'gold', 'kill', 'death', 'tower', 'inhib', 'dragon', 'baron']\n",
    "suspicious = []\n",
    "for col in X.columns:\n",
    "    col_lower = col.lower()\n",
    "    for keyword in keywords:\n",
    "        if keyword in col_lower:\n",
    "            suspicious.append(col)\n",
    "            print(f\"   ‚ö†Ô∏è  {col}\")\n",
    "            break\n",
    "\n",
    "if not suspicious:\n",
    "    print(\"   ‚úÖ No se encontraron columnas sospechosas obvias\")\n",
    "\n",
    "# 8. CORRELACI√ìN PERFECTA\n",
    "print(\"\\n8Ô∏è‚É£  B√öSQUEDA DE CORRELACIONES PERFECTAS:\")\n",
    "print(\"=\"*60)\n",
    "for col in X.columns:\n",
    "    X_col = X[col].fillna(0)\n",
    "    try:\n",
    "        correlation = np.corrcoef(X_col, y)[0, 1]\n",
    "        if abs(correlation) > 0.98:\n",
    "            print(f\"   ‚ö†Ô∏è  {col}: correlaci√≥n = {correlation:.4f}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\n‚úÖ DIAGN√ìSTICO COMPLETADO\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
