{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f9444d",
   "metadata": {},
   "source": [
    "# Combinacions d'herois\n",
    "\n",
    "**NOTA:** Moltes de les funcions que s'utilitzen estan en el document **Combinacions_herois.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar llibreries necessàries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from Dades_Individuals import *\n",
    "from Combinacions_herois import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = pd.read_csv(\"../../LOL - Dataset/games.csv\")\n",
    "DataSet_champions = carregar_herois_cache()\n",
    "\n",
    "# Primer mirem quines són totalment identiques\n",
    "duplicated_rows = DataSet[DataSet.duplicated(keep=False)]\n",
    "num_duplicated_rows = len(duplicated_rows)\n",
    "\n",
    "# Si n'hi ha, les eliminem\n",
    "DataSet_cleaned = DataSet.drop_duplicates()\n",
    "DataSet_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cc53b",
   "metadata": {},
   "source": [
    "Per poder visualitzar de manera més clara totes les columne que necessitem podem eliminar aquelles que, en aquest moment, no anem a utilitzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08527d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnes_a_eliminar = [\n",
    "    'creationTime', 'gameDuration', 'seasonId'\n",
    "]\n",
    "\n",
    "DataSet_herois = DataSet_cleaned.drop(columnes_a_eliminar, axis=1)\n",
    "print(f\"Columnes eliminades correctament\")\n",
    "print(f\"Columnes restants: {list(DataSet_herois.columns)}\")\n",
    "print(f\"Dimensions del dataset: {DataSet_herois.shape}\")\n",
    "DataSet_herois.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295caaa6",
   "metadata": {},
   "source": [
    "## Preparació dades\n",
    "Comencem utilitzant la funció **comptar_combinacions_equip**, la qual ens ajuda a codificar les diferents combinacions d'herois per equip, d'aquesta manera és molt més facil jugar amb les dades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac18b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna un diccionari per poder descodificar les combinacions d'equips\n",
    "combinacions_equip = comptar_combinacions_equip(DataSet_cleaned)\n",
    "\n",
    "# Creem un nou DataFrame amb els index de les combinacions d'equips 1 i 2 \n",
    "combinacions_equip_list = list(combinacions_equip.keys())\n",
    "combinacions_equips_df = pd.DataFrame(combinacions_equip_list, columns=['champ1_id', 'champ2_id', 'champ3_id', 'champ4_id', 'champ5_id'])\n",
    "combinacions_equips_df\n",
    "combinacions_equips_df['spell_index'] = range(len(combinacions_equips_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6811f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la funció completa\n",
    "DataSet_reduit = afegir_combinacions_equips_a_dataset(\n",
    "    df=DataSet_herois,\n",
    "    combinacions_equips_df=combinacions_equips_df,\n",
    ")\n",
    "\n",
    "print(f\"Dimensions del dataset reduït: {DataSet_reduit.shape}\")\n",
    "print(f\"Columnes reduïdes: {list(DataSet_reduit.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar les primeres files\n",
    "DataSet_reduit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd781d",
   "metadata": {},
   "source": [
    "## Herois\n",
    "Visualitzem les dades dels herois a continaució."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc6e94e",
   "metadata": {},
   "source": [
    "### Equip 1\n",
    "Observem quines de les combinacions de l'equip 1 s'ha utilitzat més, quin és el seu percentatge de victoria i mirar de quins herois esta compost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim les dades on l'equip 1 ha guanyat\n",
    "DataSet_herois_1 = DataSet_reduit[DataSet_reduit['winner'] == 1]\n",
    "count = DataSet_herois_1['team1_comb_index'].value_counts()\n",
    "\n",
    "max = count.max()\n",
    "min = count.min()\n",
    "\n",
    "print(f\"El nombre màxim de combinacions d'herois que ha guanyat un equip és: {max}\")\n",
    "print(f\"El nombre mínim de combinacions d'herois que ha guanyat un equip és: {min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos_recomanats = crear_grafica_i_analisi_de_combinacions_guanyades(DataSet_reduit, 'team1_comb_index', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca98c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les dades dels herois recomanats en format DataFrame\n",
    "print(\"=\"*80)\n",
    "print(\"DADES DELS HEROIS A LES COMBINACIONS RECOMANADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "herois_data = obtenir_dades_herois(combos_recomanats, combinacions_equips_df)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_herois_recomanats = pd.DataFrame(herois_data)\n",
    "\n",
    "print(\"\\nDataFrame amb els herois de les combinacions recomanades:\")\n",
    "print(\"=\"*80)\n",
    "print(df_herois_recomanats.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mostrar estadístiques\n",
    "print(f\"\\nTotal de combinacions: {df_herois_recomanats['combo_idx'].nunique()}\")\n",
    "print(f\"Total de herois únics: {df_herois_recomanats['heroi_id'].nunique()}\")\n",
    "\n",
    "df_herois_recomanats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98845635",
   "metadata": {},
   "source": [
    "En aquest cas, només ens trobem amb un cas que obté una taxa de victòria de més del 90%, del 100%. Com podem apreciar, en les dades de cadascun dels herois, observem que tenen un tag que determina quines accions o quines són les seves responsabilitats. \n",
    "\n",
    "**Nota:** Tenim en compte que en aquest cas tingui un 100% de taxa de victòria pot ser enganyos.\n",
    "\n",
    "Només em obtingut una combinació amb una taxa alta, crec que el millor pas, en aquest cas, seria mirar contra quins herois estaven competint, però això ho veurem més endavant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429ad5c",
   "metadata": {},
   "source": [
    "El següent punt a observar és quins tags són els més utilitzats, quin és l'equilibri entre la quantitat de tags que té una combinació d'herois i la taxa de victoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "herois_team1_win_com = count.copy()\n",
    "\n",
    "data_herois = obtenir_dades_herois(herois_team1_win_com, combinacions_equips_df)\n",
    "data_herois_df = pd.DataFrame(data_herois)\n",
    "tags_count = data_herois_df['tags'].value_counts()\n",
    "len(tags_count)\n",
    "tags_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_herois_df['tags'] = data_herois_df['tags'].str.split(',')\n",
    "\n",
    "# Després fer el mateix procés\n",
    "tags_exploded = data_herois_df['tags'].explode()\n",
    "tags_count_ind = tags_exploded.value_counts()\n",
    "\n",
    "tags_count_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39525b37",
   "metadata": {},
   "source": [
    "Amb aquesta comparativa podem extreure les següents conclusions:\n",
    "- El Tag d'heroi més utilitzat és el de **Mage**.\n",
    "    - En la majoria de les combinacions de Tag, sempre està.\n",
    "- No importa el Tag sol, sinó la combinació d'ells per determinar quin és l'heroi que millor funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37699763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir tags més comuns\n",
    "top_n = 5\n",
    "top_tags = data_herois_df['tags'].dropna().explode().value_counts().head(top_n).index\n",
    "top_tags_set = set(top_tags)\n",
    "\n",
    "# Crear una columna temporal amb el nombre de tags coincidents\n",
    "def count_matching_tags(tags_list):\n",
    "    if not isinstance(tags_list, list):\n",
    "        return 0\n",
    "    return sum(1 for tag in tags_list if tag in top_tags_set)\n",
    "\n",
    "data_herois_df['matching_tags_count'] = data_herois_df['tags'].apply(count_matching_tags)\n",
    "\n",
    "# Filtrar herois amb almenys 1 tag coincident i ordenar per rellevància\n",
    "millors_herois_df = data_herois_df[data_herois_df['matching_tags_count'] > 0]\n",
    "millors_herois_df = millors_herois_df.sort_values('matching_tags_count', ascending=False)\n",
    "\n",
    "# Eliminar la columna temporal (opcional)\n",
    "millors_herois_df = millors_herois_df.drop(columns=['matching_tags_count'])\n",
    "\n",
    "# Guardar en llista\n",
    "millors_herois = millors_herois_df.to_dict('records')\n",
    "millors_herois_df = pd.DataFrame(millors_herois)\n",
    "print(f\"Obtenim un total de {len(millors_herois)} que tenen les 5 combinacions de tags amb més victories ({top_tags})\")\n",
    "\n",
    "millors_herois_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6984ac6",
   "metadata": {},
   "source": [
    "D'acord, ara que tenim això, podem fer una comparativa amb el següent equip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0361",
   "metadata": {},
   "source": [
    "### Equip 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f88707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim les dades on l'equip 2 ha guanyat\n",
    "DataSet_herois_2 = DataSet_reduit[DataSet_reduit['winner'] == 2]\n",
    "count = DataSet_herois_2['team2_comb_index'].value_counts()\n",
    "\n",
    "max_val = count.max()\n",
    "min_val = count.min()\n",
    "\n",
    "print(f\"El nombre màxim de combinacions d'herois que ha guanyat un equip és: {max_val}\")\n",
    "print(f\"El nombre mínim de combinacions d'herois que ha guanyat un equip és: {min_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b725d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos_recomanats = crear_grafica_i_analisi_de_combinacions_guanyades(DataSet_reduit, 'team2_comb_index', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les dades dels herois recomanats en format DataFrame\n",
    "print(\"=\"*80)\n",
    "print(\"DADES DELS HEROIS A LES COMBINACIONS RECOMANADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "herois_recomanats_data = obtenir_dades_herois(combos_recomanats, combinacions_equips_df)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_herois_recomanats = pd.DataFrame(herois_recomanats_data)\n",
    "\n",
    "print(\"\\nDataFrame amb els herois de les combinacions recomanades:\")\n",
    "print(\"=\"*80)\n",
    "print(df_herois_recomanats.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mostrar estadístiques\n",
    "print(f\"\\nTotal de combinacions: {df_herois_recomanats['combo_idx'].nunique()}\")\n",
    "print(f\"Total de herois únics: {df_herois_recomanats['heroi_id'].nunique()}\")\n",
    "\n",
    "df_herois_recomanats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a606fd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "herois_team2_win_com = count.copy()\n",
    "\n",
    "data_herois = obtenir_dades_herois(herois_team2_win_com, combinacions_equips_df)\n",
    "data_herois_df = pd.DataFrame(data_herois)\n",
    "tags_count = data_herois_df['tags'].value_counts()\n",
    "len(tags_count)\n",
    "tags_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir tags més comuns\n",
    "top_n = 5\n",
    "top_tags = data_herois_df['tags'].dropna().explode().value_counts().head(top_n).index\n",
    "top_tags_set = set(top_tags)\n",
    "\n",
    "# Crear una columna temporal amb el nombre de tags coincidents\n",
    "def count_matching_tags(tags_list):\n",
    "    if not isinstance(tags_list, list):\n",
    "        return 0\n",
    "    return sum(1 for tag in tags_list if tag in top_tags_set)\n",
    "\n",
    "data_herois_df['matching_tags_count'] = data_herois_df['tags'].apply(count_matching_tags)\n",
    "\n",
    "# Filtrar herois amb almenys 1 tag coincident i ordenar per rellevància\n",
    "millors_herois_df = data_herois_df[data_herois_df['matching_tags_count'] > 0]\n",
    "millors_herois_df = millors_herois_df.sort_values('matching_tags_count', ascending=False)\n",
    "\n",
    "# Eliminar la columna temporal (opcional)\n",
    "millors_herois_df = millors_herois_df.drop(columns=['matching_tags_count'])\n",
    "\n",
    "# Guardar en llista\n",
    "millors_herois = millors_herois_df.to_dict('records')\n",
    "millors_herois_df = pd.DataFrame(millors_herois)\n",
    "print(f\"Obtenim un total de {len(millors_herois)} que tenen les 5 combinacions de tags amb més victories ({top_tags})\")\n",
    "\n",
    "millors_herois_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af57547",
   "metadata": {},
   "source": [
    "### Combinació entre els herois de cada equip\n",
    "Anem a comparar les combinacions de campions de cada equip i comparar-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = analisi_profund_combinacions_compartides(DataSet_reduit, combinacions_equips_df)\n",
    "resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931e39a",
   "metadata": {},
   "source": [
    "Ens em trobat amb **92 combinacions de campions** els quals s'han fet servir pels dos equips anteriorment i que han guanyat.\n",
    "\n",
    "A continuació, mirarem quines combinacions han funcionat correctamet per un equip, però malament amb l'altre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equip 1\n",
    "obtenir_combinacions_unilaterals(DataSet_reduit, 1)\n",
    "# Equip 2\n",
    "\n",
    "obtenir_combinacions_unilaterals(DataSet_reduit, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ecedfa",
   "metadata": {},
   "source": [
    "Per sorpresa no trobem a **cap** combinació que funcioni millor en un equip que en un altre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6dacf4",
   "metadata": {},
   "source": [
    "#### Correlacions entre combinacions\n",
    "Analitzar correlacions entre diferents combinacions de campions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANÀLISI 1: Correlacions entre combinacions similars\")\n",
    "correl_df, win_rates, combos_sel = analitzar_correlacions_performance_optimitzat(\n",
    "    DataSet_reduit, \n",
    "    combinacions_equips_df,\n",
    "    top_n=200  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a909e32",
   "metadata": {},
   "source": [
    "Aquí tenim un problema , sens diu que hi ha un total de **101499 combinacions úniques**, però sabem que no ja que la funció \"analisi_profund_combinacions_compartides\" havia determinat **50470 combinacions úniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1acf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_partides = len(DataSet_reduit)\n",
    "combinacions_úniques = 101449\n",
    "ratio = combinacions_úniques/total_partides\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784fc32",
   "metadata": {},
   "source": [
    "Ara podem determinar que cada partida té combinacions úniques. Gairabé no es repeteixen.\n",
    "\n",
    "- Les combinacions no es reutilitzen\n",
    "- No es poden trobar \"millors combinacions\" perquè cada una només apareix 1-2 vegades.\n",
    "- Que obtinguem un **winrate = 100%** no és significatiu, ja que només pot haver guanyat 1 o 2 partides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar l'anàlisi real\n",
    "diversitat = analisi_real_diversitat(DataSet_reduit, combinacions_equips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e584d",
   "metadata": {},
   "source": [
    "Aquests gràfics demostren les nostres conclusions anteriors, moltes d'aquestes combinacions només apareixen 1 vegada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83d69e",
   "metadata": {},
   "source": [
    "#### Correlacions contra combinacions comunes\n",
    "Analitzar correlacions contra combinacions comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955330d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nANÀLISI 2: Rendiment contra combinacions comunes\")\n",
    "try:\n",
    "    resultats_contra, enfrontaments = analitzar_correlacions_contra_comunes_optimitzat(\n",
    "        DataSet_reduit,\n",
    "        combinacions_equips_df,\n",
    "        min_partides=0  # Encara més baix!\n",
    "    )\n",
    "    \n",
    "    if resultats_contra is not None and len(resultats_contra) > 0:\n",
    "        print(f\"\\nAnàlisi completat. Combinacions analitzades: {len(resultats_contra)}\")\n",
    "    else:\n",
    "        print(\"\\nAnàlisi completat però amb poques dades.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError durant l'anàlisi: {e}\")\n",
    "    resultats_contra, enfrontaments = pd.DataFrame(), {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab19607",
   "metadata": {},
   "source": [
    "La funció s'ha anat provant amb un valor diferent (X = 0,1,2,3) de *min_partides*. Però fins i tot en **X=0** ens marca que en 101.449 combinacions úniques d'herois, **cap parell d'aquestes combinacions s'ha enfrontat mútuament en suficients partides** per poder analitzar, ni tan sols en 2 partides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b2fcd",
   "metadata": {},
   "source": [
    "#### Patrons de Sinergia entre combinacions\n",
    "Analitzar patrons de sinergia entre herois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nANÀLISI 3: Patterns de sinergia entre herois\")\n",
    "# Primer obtenir herois_data\n",
    "herois_data = {}\n",
    "herois_json = carregar_herois_cache()\n",
    "if 'data' in herois_json:\n",
    "    for champ_info in herois_json['data'].values():\n",
    "        if 'id' in champ_info:\n",
    "            herois_data[champ_info['id']] = champ_info\n",
    "\n",
    "sinergia_df = analitzar_patterns_sinergia(\n",
    "    DataSet_reduit, combinacions_equips_df, herois_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234591a",
   "metadata": {},
   "source": [
    "D'acord, ara que sabem que hi ha certa sinergia entre algusns campions, en el cas que un equip tingui aquesta combinació podriem crear una nova columna per determinar aquest avantatge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a932a",
   "metadata": {},
   "source": [
    "#### Anàlisi per Herois Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17219d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Executar anàlisi per herois individuals\n",
    "print(\"\\n\\n1. ANÀLISI PER HEROIS INDIVIDUALS:\")\n",
    "heroi_stats = analisi_alternatiu_per_herois(\n",
    "    DataSet_reduit, \n",
    "    DataSet_herois,\n",
    "    combinacions_equips_df,\n",
    "    min_partides=30  # Pots ajustar aquest llindar\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41368a54",
   "metadata": {},
   "source": [
    "##### Exepcions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275c75b",
   "metadata": {},
   "source": [
    "- Pick rate alt, win_rate baix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41bce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heroi_stats[heroi_stats['pick_rate'] > 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "herois1 = sinergia_df[sinergia_df['heroi1_id'] == 412]\n",
    "herois2 = sinergia_df[sinergia_df['heroi2_id'] == 412]\n",
    "\n",
    "num = len(herois1) + len(herois2)\n",
    "mitjana = (sum(herois1['score_sinergia']) + sum(herois2['score_sinergia']))/num\n",
    "mes = len(sinergia_df[sinergia_df['score_sinergia'] > mitjana])\n",
    "\n",
    "print(f\"Num parelles: {num}\")\n",
    "print(f\"Mitjana sineriga amb parelles: {mitjana}\")\n",
    "print(f\"Parelles amb més score_sinergia {mitjana}: {mes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefdc854",
   "metadata": {},
   "source": [
    "Sabem que el campio \"Thresh\", l'excepció del campió, sorprent ja que té un total de 137 parelles amb només un **score_sinergia del 0.24** i hi han 4964 parelles amb més sinergia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a73ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3a5193",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6080b4b1",
   "metadata": {},
   "source": [
    "#### Anàlisi per Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18213eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n2. ANÀLISI PER TAGS/ROLS:\")\n",
    "composicions_stats, tag_stats = analisi_per_tags(\n",
    "    DataSet_reduit,\n",
    "    DataSet_herois,\n",
    "    combinacions_equips_df,\n",
    "    min_partides=3  \n",
    ")\n",
    "\n",
    "# 4. Comparar resultats\n",
    "if heroi_stats is not None:\n",
    "    print(f\"\\n✓ Anàlisi per herois completat: {len(heroi_stats)} herois analitzats\")\n",
    "\n",
    "if composicions_stats is not None:\n",
    "    print(f\"✓ Anàlisi per tags completat: {len(composicions_stats)} composicions analitzades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac18db44",
   "metadata": {},
   "source": [
    "# Implementacions al dataset per millor entrenament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469daba0",
   "metadata": {},
   "source": [
    "D'acord, ara que sé que moltes d'aquestes combinacions entre campions no és repeteixen i només s'utilitzen entre 1 o 2 partides, no tenim proutes partides per determinar si hi ha alguan possible relació entre elles que marqui que una partida tingui més probabilitat que guanyi un equip o l'altre.\n",
    "\n",
    "L'analisi dels herois individuals és bastant favorable, però no crec que només valorar el win_rate dels jugadors, ja que com és un joc de treball en equip, també hauriem de tenir en compte les dades dels jugadors, quins percentatges d'ús del campió tenen els jugadors, quin són els seus index i destresa, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22984f",
   "metadata": {},
   "source": [
    "### Sinergia entre parelles de campions\n",
    "El que si que em pogut descorbrir i que crec que el podem utilitzar és la sinergia que hi ha entre els diferents herois en un mateix equip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_sinergia_equips(DataSet_reduit, combinacions_equips_df, sinergia_df):\n",
    "    \"\"\"\n",
    "    Calcula el score de sinergia promig per a cada equip i l'afegeix a la base de dades.\n",
    "    \n",
    "    Args:\n",
    "        DataSet_reduit: DataFrame amb les dades de partides\n",
    "        combinacions_equips_df: DataFrame amb les combinacions d'equips\n",
    "        sinergia_df: DataFrame amb les sinergies de parelles (generat per analitzar_patterns_sinergia)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame amb les noves columnes de sinergia afegides\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    \n",
    "    # Crear un diccionari ràpid per a cercar sinergies de parelles\n",
    "    sinergia_dict = {}\n",
    "    for _, row in sinergia_df.iterrows():\n",
    "        # Crear una clau única ordenada per a la parella\n",
    "        key = tuple(sorted([int(row['heroi1_id']), int(row['heroi2_id'])]))\n",
    "        sinergia_dict[key] = row['score_sinergia']\n",
    "    \n",
    "    # Funció per obtenir herois d'una combinació\n",
    "    def obtenir_herois_combinacio(comb_index):\n",
    "        if comb_index in combinacions_equips_df.index:\n",
    "            row = combinacions_equips_df.loc[comb_index]\n",
    "            return [\n",
    "                int(row['champ1_id']),\n",
    "                int(row['champ2_id']),\n",
    "                int(row['champ3_id']),\n",
    "                int(row['champ4_id']),\n",
    "                int(row['champ5_id'])\n",
    "            ]\n",
    "        return []\n",
    "    \n",
    "    # Funció per calcular sinergia d'un equip\n",
    "    def calcular_sinergia_promig_equip(herois):\n",
    "        if len(herois) != 5:\n",
    "            return 0.5  # Valor per defecte si no hi ha 5 herois\n",
    "        \n",
    "        # Generar totes les parelles possibles (10 parelles en total)\n",
    "        parelles = list(itertools.combinations(sorted(herois), 2))\n",
    "        \n",
    "        # Obtenir scores de sinergia per a cada parella\n",
    "        scores = []\n",
    "        for parella in parelles:\n",
    "            key = tuple(sorted(parella))\n",
    "            score = sinergia_dict.get(key, 0.5)  # 0.5 per defecte si no hi ha dades\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Calcular promig, normalitzat perquè no sigui 1.0 perfecte\n",
    "        if scores:\n",
    "            sinergia_promig = np.mean(scores)\n",
    "            # Normalitzem lleugerament per evitar valors extrems\n",
    "            sinergia_promig = 0.5 + (sinergia_promig - 0.5) * 0.9\n",
    "            return np.minimum(sinergia_promig, 0.95)  # CORREGIT: np.minimum en lloc de min\n",
    "        return 0.5\n",
    "    \n",
    "    # Calcular sinergia per a cada equip en cada partida\n",
    "    team1_sinergies = []\n",
    "    team2_sinergies = []\n",
    "    \n",
    "    for idx, row in DataSet_reduit.iterrows():\n",
    "        # Obtenir herois de cada equip\n",
    "        herois_team1 = obtenir_herois_combinacio(row['team1_comb_index'])\n",
    "        herois_team2 = obtenir_herois_combinacio(row['team2_comb_index'])\n",
    "        \n",
    "        # Calcular sinergia promig\n",
    "        sinergia_team1 = calcular_sinergia_promig_equip(herois_team1)\n",
    "        sinergia_team2 = calcular_sinergia_promig_equip(herois_team2)\n",
    "        \n",
    "        team1_sinergies.append(sinergia_team1)\n",
    "        team2_sinergies.append(sinergia_team2)\n",
    "    \n",
    "    # Afegir columnes a la base de dades\n",
    "    DataSet_reduit['team1_sinergia_promig'] = team1_sinergies\n",
    "    DataSet_reduit['team2_sinergia_promig'] = team2_sinergies\n",
    "    \n",
    "    # Calcular diferència de sinergia (pot ser útil per al model)\n",
    "    DataSet_reduit['sinergia_diferencia'] = DataSet_reduit['team1_sinergia_promig'] - DataSet_reduit['team2_sinergia_promig']\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ESTADÍSTIQUES DE SINERGIA AFEGIDES\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Team1 Sinergia Promig: {DataSet_reduit['team1_sinergia_promig'].mean():.3f}\")\n",
    "    print(f\"Team2 Sinergia Promig: {DataSet_reduit['team2_sinergia_promig'].mean():.3f}\")\n",
    "    print(f\"Diferència Mitjana: {DataSet_reduit['sinergia_diferencia'].mean():.3f}\")\n",
    "    \n",
    "    return DataSet_reduit\n",
    "\n",
    "\n",
    "def analitzar_patterns_sinergia(DataSet_reduit, combinacions_equips_df, herois_data):\n",
    "    \"\"\"\n",
    "    Identifica patterns de sinergia entre herois basat en co-ocurrència i win rate.\n",
    "    Modificada per integrar-se amb el flux de modificació de la base de dades.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ANÀLISI DE SINERGIA ENTRE HEROIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Crear diccionari d'herois per combinació\n",
    "    combo_herois = {}\n",
    "    for idx, row in combinacions_equips_df.iterrows():\n",
    "        herois = [int(row['champ1_id']), int(row['champ2_id']), \n",
    "                 int(row['champ3_id']), int(row['champ4_id']), \n",
    "                 int(row['champ5_id'])]\n",
    "        combo_herois[idx] = herois\n",
    "    \n",
    "    # 2. Analitzar totes les parelles possibles d'herois\n",
    "    parelles_stats = defaultdict(list)\n",
    "    \n",
    "    for combo_idx, herois in combo_herois.items():\n",
    "        # Generar totes les parelles úniques d'aquesta combinació\n",
    "        parelles = list(itertools.combinations(sorted(herois), 2))\n",
    "        \n",
    "        # Obtenir win rate d'aquesta combinació\n",
    "        mascara_team1 = DataSet_reduit['team1_comb_index'] == combo_idx\n",
    "        mascara_team2 = DataSet_reduit['team2_comb_index'] == combo_idx\n",
    "        \n",
    "        victorias = (DataSet_reduit.loc[mascara_team1, 'winner'] == 1).sum() + \\\n",
    "                   (DataSet_reduit.loc[mascara_team2, 'winner'] == 2).sum()\n",
    "        partides = mascara_team1.sum() + mascara_team2.sum()\n",
    "        win_rate = victorias / partides if partides > 0 else 0.5\n",
    "        \n",
    "        # Afegir win rate a cada parella d'aquesta combinació\n",
    "        for parella in parelles:\n",
    "            parelles_stats[parella].append(win_rate)\n",
    "    \n",
    "    # 3. Calcular estadístiques per a cada parella\n",
    "    results = []\n",
    "    for parella, win_rates in parelles_stats.items():\n",
    "        if len(win_rates) >= 2:  # Reduït a mínim 2 aparacions per tenir més dades\n",
    "            avg_win_rate = np.mean(win_rates)\n",
    "            std_win_rate = np.std(win_rates) if len(win_rates) > 1 else 0.1\n",
    "            aparicions = len(win_rates)\n",
    "            \n",
    "            # Obtenir noms dels herois\n",
    "            heroi1_nom = herois_data.get(parella[0], {}).get('name', f'ID:{parella[0]}')\n",
    "            heroi2_nom = herois_data.get(parella[1], {}).get('name', f'ID:{parella[1]}')\n",
    "            \n",
    "            # Calcular consistència (inversa de la variabilitat)\n",
    "            consistencia = 1 - (std_win_rate / np.maximum(avg_win_rate, 0.1))\n",
    "            consistencia = np.clip(consistencia, 0, 1)  # Normalitzar entre 0 i 1\n",
    "            \n",
    "            # Calcular score de sinergia (més equilibrat)\n",
    "            # Combina win rate i consistència, amb pes per aparicions\n",
    "            pes_aparicions = np.minimum(aparicions / 10, 1)  # CORREGIT: np.minimum en lloc de min\n",
    "            score_sinergia = (avg_win_rate * 0.6 + consistencia * 0.4) * pes_aparicions\n",
    "            \n",
    "            results.append({\n",
    "                'heroi1_id': parella[0],\n",
    "                'heroi2_id': parella[1],\n",
    "                'heroi1_nom': heroi1_nom,\n",
    "                'heroi2_nom': heroi2_nom,\n",
    "                'aparicions': aparicions,\n",
    "                'win_rate_promig': avg_win_rate,\n",
    "                'win_rate_std': std_win_rate,\n",
    "                'consistencia': consistencia,\n",
    "                'score_sinergia': score_sinergia\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # Ordenar per millor sinergia\n",
    "        results_df = results_df.sort_values('score_sinergia', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nParelles analitzades: {len(results_df)}\")\n",
    "        print(\"\\nTOP 10 PARELLES AMB MILLOR SINERGIA:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for idx, row in results_df.head(10).iterrows():\n",
    "            print(f\"{row['heroi1_nom']:15} + {row['heroi2_nom']:15} | \"\n",
    "                  f\"WR: {row['win_rate_promig']:.2%} | \"\n",
    "                  f\"Sinergia: {row['score_sinergia']:.3f} | \"\n",
    "                  f\"Aparicions: {row['aparicions']}\")\n",
    "        \n",
    "        # Estadístiques generals\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ESTADÍSTIQUES GENERALS DE SINERGIA:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Score sinergia mitjà: {results_df['score_sinergia'].mean():.3f}\")\n",
    "        print(f\"Score sinergia màxim: {results_df['score_sinergia'].max():.3f}\")\n",
    "        print(f\"Score sinergia mínim: {results_df['score_sinergia'].min():.3f}\")\n",
    "        \n",
    "        # Histograma de scores\n",
    "        print(\"\\nDistribució de scores de sinergia:\")\n",
    "        bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        hist, _ = np.histogram(results_df['score_sinergia'], bins=bins)\n",
    "        for i in range(len(bins)-1):\n",
    "            print(f\"  {bins[i]:.1f}-{bins[i+1]:.1f}: {hist[i]} parelles\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "# FLUX COMPLET D'IMPLEMENTACIÓ\n",
    "def implementar_sinergia_model(DataSet_reduit, combinacions_equips_df):\n",
    "    \"\"\"\n",
    "    Flux complet per implementar la sinergia al model.\n",
    "    \n",
    "    1. Analitza les sinergies entre parelles\n",
    "    2. Calcula el score de sinergia promig per equip\n",
    "    3. Afegeix les columnes a la base de dades original\n",
    "    \"\"\"\n",
    "    # 1. Carregar dades dels herois\n",
    "    herois_json = carregar_herois_cache()\n",
    "    herois_data = {}\n",
    "    if 'data' in herois_json:\n",
    "        for champ_info in herois_json['data'].values():\n",
    "            if 'id' in champ_info:\n",
    "                herois_data[champ_info['id']] = champ_info\n",
    "    \n",
    "    # 2. Analitzar sinergies entre parelles\n",
    "    sinergia_df = analitzar_patterns_sinergia(DataSet_reduit, combinacions_equips_df, herois_data)\n",
    "    \n",
    "    # 3. Calcular sinergia per equips i afegir a la base de dades\n",
    "    DataSet_amb_sinergia = calcular_sinergia_equips(DataSet_reduit.copy(), combinacions_equips_df, sinergia_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMPLEMENTACIÓ COMPLETADA\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Columnes afegides: team1_sinergia_promig, team2_sinergia_promig, sinergia_diferencia\")\n",
    "    print(f\"Total de files processades: {len(DataSet_amb_sinergia)}\")\n",
    "    \n",
    "    return DataSet_amb_sinergia, sinergia_df\n",
    "\n",
    "\n",
    "DataSet_amb_sinergia, sinergia_df =implementar_sinergia_model(DataSet_reduit, combinacions_equips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355b23a",
   "metadata": {},
   "source": [
    "### Tags\n",
    "S'ha trobat una correlació entre els diferents tags que tenen la combinació d'herois amb percentatge més alt que d'altres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisi_per_tags(DataSet_reduit, DataSet_herois, combinacions_equips_df, min_partides=5):\n",
    "    \"\"\"\n",
    "    Analitza el rendiment basat en composicions de tags/rols i afegeix score de tags a DataSet_reduit.\n",
    "    Retorna DataSet_reduit amb noves columnes: team1_tag_score, team2_tag_score, tag_score_diff.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from collections import Counter, defaultdict\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ANÀLISI PER TAGS/ROLS I CÀLCUL DE SCORE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. CARREGAR I PREPARAR DADES D'HEROIS\n",
    "    herois_data = carregar_herois_cache()\n",
    "    \n",
    "    heroi_to_tags = {}\n",
    "    all_tags = set()\n",
    "    \n",
    "    if 'data' in herois_data:\n",
    "        for champ_info in herois_data['data'].values():\n",
    "            if 'id' in champ_info:\n",
    "                heroi_id = champ_info['id']\n",
    "                tags = champ_info.get('tags', [])\n",
    "                if isinstance(tags, list):\n",
    "                    heroi_to_tags[heroi_id] = tags\n",
    "                    all_tags.update(tags)\n",
    "    \n",
    "    print(f\"\\n1. TAGS ÚNIQUES IDENTIFICATS: {len(all_tags)}\")\n",
    "    print(f\"   Tags: {', '.join(sorted(all_tags))}\")\n",
    "    \n",
    "    # 2. PREPROCESSAR SIGNATURES DE TAGS PER COMBINACIONS D'EQUIP\n",
    "    print(\"\\n2. PREPROCESSANT SIGNATURES DE TAGS PER COMBINACIONS D'EQUIP...\")\n",
    "    \n",
    "    combo_to_signatura = {}\n",
    "    signatura_to_combos = defaultdict(list)\n",
    "    \n",
    "    for combo_idx, row in combinacions_equips_df.iterrows():\n",
    "        herois = [int(row['champ1_id']), int(row['champ2_id']), \n",
    "                  int(row['champ3_id']), int(row['champ4_id']), \n",
    "                  int(row['champ5_id'])]\n",
    "        \n",
    "        tags_equip = []\n",
    "        for hero_id in herois:\n",
    "            if hero_id in heroi_to_tags:\n",
    "                tags_equip.extend(heroi_to_tags[hero_id])\n",
    "        \n",
    "        tag_counter = Counter(tags_equip)\n",
    "        key_parts = []\n",
    "        for tag in sorted(all_tags):\n",
    "            if tag in tag_counter:\n",
    "                key_parts.append(f\"{tag}:{tag_counter[tag]}\")\n",
    "        \n",
    "        signatura = \",\".join(key_parts) if key_parts else \"empty\"\n",
    "        combo_to_signatura[combo_idx] = signatura\n",
    "        signatura_to_combos[signatura].append(combo_idx)\n",
    "    \n",
    "    print(f\"   Combinacions processades: {len(combo_to_signatura)}\")\n",
    "    print(f\"   Signatures úniques: {len(signatura_to_combos)}\")\n",
    "    \n",
    "    # 3. CALCULAR ESTADÍSTIQUES PER SIGNATURA\n",
    "    print(\"\\n3. CALCULANT ESTADÍSTIQUES PER SIGNATURA...\")\n",
    "    \n",
    "    signatura_stats = defaultdict(lambda: {'wins': 0, 'games': 0})\n",
    "    total_partides = len(DataSet_herois)\n",
    "    \n",
    "    for idx, row in DataSet_herois.iterrows():\n",
    "        winner = row['winner']\n",
    "        \n",
    "        for team in [1, 2]:\n",
    "            tags_equip = []\n",
    "            for champ in range(1, 6):\n",
    "                col_name = f't{team}_champ{champ}id'\n",
    "                hero_id = row[col_name]\n",
    "                if pd.notna(hero_id):\n",
    "                    hero_id = int(hero_id)\n",
    "                    if hero_id in heroi_to_tags:\n",
    "                        tags_equip.extend(heroi_to_tags[hero_id])\n",
    "            \n",
    "            tag_counter = Counter(tags_equip)\n",
    "            key_parts = []\n",
    "            for tag in sorted(all_tags):\n",
    "                if tag in tag_counter:\n",
    "                    key_parts.append(f\"{tag}:{tag_counter[tag]}\")\n",
    "            signatura = \",\".join(key_parts) if key_parts else \"empty\"\n",
    "            \n",
    "            signatura_stats[signatura]['games'] += 1\n",
    "            equip_guanya = (team == 1 and winner == 1) or (team == 2 and winner == 2)\n",
    "            if equip_guanya:\n",
    "                signatura_stats[signatura]['wins'] += 1\n",
    "    \n",
    "    print(f\"   Partides processades: {total_partides}\")\n",
    "    print(f\"   Signatures amb dades: {len(signatura_stats)}\")\n",
    "    \n",
    "    # 4. CALCULAR WIN_RATE PER TAG INDIVIDUAL\n",
    "    print(\"\\n4. CALCULANT WIN_RATE PER TAG INDIVIDUAL...\")\n",
    "    \n",
    "    tag_stats = defaultdict(lambda: {'wins': 0, 'games': 0})\n",
    "    \n",
    "    for idx, row in DataSet_herois.iterrows():\n",
    "        winner = row['winner']\n",
    "        for team in [1, 2]:\n",
    "            tags_equip = []\n",
    "            for champ in range(1, 6):\n",
    "                hero_id = row[f't{team}_champ{champ}id']\n",
    "                if pd.notna(hero_id):\n",
    "                    hero_id = int(hero_id)\n",
    "                    if hero_id in heroi_to_tags:\n",
    "                        tags_equip.extend(heroi_to_tags[hero_id])\n",
    "            \n",
    "            equip_guanya = (team == 1 and winner == 1) or (team == 2 and winner == 2)\n",
    "            for tag in set(tags_equip):\n",
    "                tag_stats[tag]['games'] += 1\n",
    "                if equip_guanya:\n",
    "                    tag_stats[tag]['wins'] += 1\n",
    "    \n",
    "    tag_win_rates = {}\n",
    "    for tag, stats in tag_stats.items():\n",
    "        if stats['games'] > 0:\n",
    "            tag_win_rates[tag] = stats['wins'] / stats['games']\n",
    "        else:\n",
    "            tag_win_rates[tag] = 0.5\n",
    "    \n",
    "    # 5. CALCULAR SCORE DE TAGS PER SIGNATURA\n",
    "    print(\"\\n5. CALCULANT SCORE DE TAGS...\")\n",
    "    \n",
    "    signatura_scores = {}\n",
    "    for signatura, stats in signatura_stats.items():\n",
    "        games = stats['games']\n",
    "        wins = stats['wins']\n",
    "        \n",
    "        if games >= min_partides:\n",
    "            score = wins / games\n",
    "        else:\n",
    "            if signatura == \"empty\":\n",
    "                score = 0.5\n",
    "            else:\n",
    "                tags_in_signatura = []\n",
    "                for part in signatura.split(','):\n",
    "                    tag, count = part.split(':')\n",
    "                    count = int(count)\n",
    "                    for _ in range(count):\n",
    "                        tags_in_signatura.append(tag)\n",
    "                \n",
    "                tags_unics = set(tags_in_signatura)\n",
    "                if tags_unics:\n",
    "                    scores_tags = [tag_win_rates.get(tag, 0.5) for tag in tags_unics]\n",
    "                    score = np.mean(scores_tags)\n",
    "                else:\n",
    "                    score = 0.5\n",
    "        \n",
    "        signatura_scores[signatura] = score\n",
    "    \n",
    "    # 6. ASSIGNAR SCORES A LES COMBINACIONS\n",
    "    combo_scores = {}\n",
    "    for combo_idx, signatura in combo_to_signatura.items():\n",
    "        combo_scores[combo_idx] = signatura_scores.get(signatura, 0.5)\n",
    "    \n",
    "    # 7. AFEGIR COLUMNES A DataSet_reduit\n",
    "    print(\"\\n6. AFEGINT SCORES DE TAGS AL DATASET...\")\n",
    "    \n",
    "    team1_scores = []\n",
    "    team2_scores = []\n",
    "    \n",
    "    for idx, row in DataSet_reduit.iterrows():\n",
    "        combo1 = row['team1_comb_index']\n",
    "        combo2 = row['team2_comb_index']\n",
    "        \n",
    "        score1 = combo_scores.get(combo1, 0.5)\n",
    "        score2 = combo_scores.get(combo2, 0.5)\n",
    "        \n",
    "        team1_scores.append(score1)\n",
    "        team2_scores.append(score2)\n",
    "    \n",
    "    DataSet_reduit['team1_tag_score'] = team1_scores\n",
    "    DataSet_reduit['team2_tag_score'] = team2_scores\n",
    "    DataSet_reduit['tag_score_diff'] = DataSet_reduit['team1_tag_score'] - DataSet_reduit['team2_tag_score']\n",
    "    \n",
    "    print(f\"   Columnes afegides: team1_tag_score, team2_tag_score, tag_score_diff\")\n",
    "    \n",
    "    # 8. ESTADÍSTIQUES I RESULTATS\n",
    "    print(\"\\n7. ESTADÍSTIQUES DE SCORES DE TAGS:\")\n",
    "    print(f\"   Team1 tag score mitjà: {DataSet_reduit['team1_tag_score'].mean():.3f}\")\n",
    "    print(f\"   Team2 tag score mitjà: {DataSet_reduit['team2_tag_score'].mean():.3f}\")\n",
    "    print(f\"   Diferència mitjana: {DataSet_reduit['tag_score_diff'].mean():.3f}\")\n",
    "    \n",
    "    # Mostrar millors composicions\n",
    "    signatura_list = []\n",
    "    for signatura, stats in signatura_stats.items():\n",
    "        games = stats['games']\n",
    "        if games > 0:\n",
    "            win_rate = stats['wins'] / games\n",
    "            signatura_list.append({\n",
    "                'signatura': signatura,\n",
    "                'partides': games,\n",
    "                'win_rate': win_rate,\n",
    "                'score': signatura_scores.get(signatura, 0.5)\n",
    "            })\n",
    "    \n",
    "    if signatura_list:\n",
    "        signatura_df = pd.DataFrame(signatura_list)\n",
    "        signatura_df = signatura_df.sort_values('win_rate', ascending=False)\n",
    "        \n",
    "        print(\"\\n   TOP 5 COMPOSICIONS DE TAGS AMB MILLOR WIN RATE:\")\n",
    "        for idx, row in signatura_df.head(5).iterrows():\n",
    "            if row['signatura'] == \"empty\":\n",
    "                desc = \"Sense tags\"\n",
    "            else:\n",
    "                parts = []\n",
    "                for part in row['signatura'].split(','):\n",
    "                    tag, count = part.split(':')\n",
    "                    parts.append(f\"{count}x {tag}\")\n",
    "                desc = \" + \".join(parts)\n",
    "            print(f\"     {desc}: WR {row['win_rate']:.1%} (score: {row['score']:.3f}) en {row['partides']} partides\")\n",
    "    \n",
    "    return DataSet_reduit\n",
    "\n",
    "\n",
    "# FLUX COMPLET PER IMPLEMENTAR TAGS AL MODEL\n",
    "def implementar_tags_model(DataSet_reduit, DataSet_herois, combinacions_equips_df, min_partides=5):\n",
    "    \"\"\"\n",
    "    Flux complet per implementar l'anàlisi de tags i afegir les columnes al model.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"IMPLEMENTANT ANÀLISI DE TAGS AL MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    DataSet_amb_tags = analisi_per_tags(\n",
    "        DataSet_reduit.copy(),\n",
    "        DataSet_herois,\n",
    "        combinacions_equips_df,\n",
    "        min_partides\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"IMPLEMENTACIÓ COMPLETADA\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Dataset original ampliat amb {len(DataSet_amb_tags)} files\")\n",
    "    print(\"Columnes afegides: team1_tag_score, team2_tag_score, tag_score_diff\")\n",
    "    \n",
    "    return DataSet_amb_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220126d",
   "metadata": {},
   "source": [
    "# Correlació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_matriu_correlacio(df, target_attribute='winner', figsize=(12, 10)):\n",
    "    \n",
    "    import seaborn as sns\n",
    "\n",
    "    # Filtrar només columnes numèriques\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df_numeric = df[numeric_columns]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"MATRIU DE CORRELACIÓ - ANÀLISI COMPLET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. MATRIU DE CORRELACIÓ COMPLETA\n",
    "    corr_matrix = df_numeric.corr()\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Màscara per amagar la triangular superior (opcional)\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    # Heatmap de correlacions\n",
    "    sns.heatmap(corr_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                fmt='.2f',\n",
    "                square=True,\n",
    "                cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title('Matriu de Correlacions - Variables Numèriques', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. CORRELACIONS AMB EL TARGET (MÉS IMPORTANT)\n",
    "    if target_attribute in df_numeric.columns:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"CORRELACIONS AMB EL TARGET: {target_attribute}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Ordenar correlacions amb el target\n",
    "        target_correlations = corr_matrix[target_attribute].sort_values(ascending=False)\n",
    "        \n",
    "        # Crear DataFrame per mostrar resultats\n",
    "        target_corr_df = pd.DataFrame({\n",
    "            'Variable': target_correlations.index,\n",
    "            'Correlació': target_correlations.values\n",
    "        })\n",
    "        \n",
    "        # Eliminar la correlació del target amb si mateix\n",
    "        target_corr_df = target_corr_df[target_corr_df['Variable'] != target_attribute]\n",
    "        \n",
    "        print(target_corr_df.to_string(index=False))\n",
    "        \n",
    "        # Gràfic de correlacions amb el target\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = ['red' if x < 0 else 'green' for x in target_corr_df['Correlació']]\n",
    "        bars = plt.barh(target_corr_df['Variable'], target_corr_df['Correlació'], color=colors, alpha=0.7)\n",
    "        \n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.axvline(x=0.3, color='blue', linestyle='--', alpha=0.5, label='Correlació moderada')\n",
    "        plt.axvline(x=-0.3, color='blue', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='Correlació forta')\n",
    "        plt.axvline(x=-0.5, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Afegir valors a les barres\n",
    "        for bar, value in zip(bars, target_corr_df['Correlació']):\n",
    "            plt.text(bar.get_width() + (0.01 if value >= 0 else -0.03), \n",
    "                    bar.get_y() + bar.get_height()/2, \n",
    "                    f'{value:.3f}', \n",
    "                    ha='left' if value >= 0 else 'right', \n",
    "                    va='center',\n",
    "                    fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Coeficient de Correlació (Pearson)')\n",
    "        plt.title(f'Correlacions de les Variables amb {target_attribute}', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. ANÀLISI DE CORRELACIONS FORTES ENTRE VARIABLES\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"CORRELACIONS FORTES ENTRE VARIABLES (multicol·linealitat)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Trobar correlacions fortes (excloent autocorrelacions)\n",
    "    strong_correlations = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_value = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.5:  # Llindar per correlació forta\n",
    "                strong_correlations.append({\n",
    "                    'Variable 1': corr_matrix.columns[i],\n",
    "                    'Variable 2': corr_matrix.columns[j],\n",
    "                    'Correlació': corr_value\n",
    "                })\n",
    "    \n",
    "    if strong_correlations:\n",
    "        strong_corr_df = pd.DataFrame(strong_correlations)\n",
    "        strong_corr_df = strong_corr_df.sort_values('Correlació', key=abs, ascending=False)\n",
    "        print(\"Correlacions fortes (> |0.5|) entre variables:\")\n",
    "        print(strong_corr_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No s'han trobat correlacions fortes (> |0.5|) entre variables\")\n",
    "    \n",
    "    # 4. RESUM DE LES VARIABLES MÉS RELLEVANTS\n",
    "    if target_attribute in df_numeric.columns:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"RESUM - VARIABLES MÉS RELLEVANTS PER AL MODEL\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Variables amb correlació forta amb el target\n",
    "        strong_target_corr = target_corr_df[abs(target_corr_df['Correlació']) > 0.05]\n",
    "        \n",
    "        if not strong_target_corr.empty:\n",
    "            print(\"Variables amb correlació forta/moderada amb el target (|r| > 0.05):\")\n",
    "            for _, row in strong_target_corr.iterrows():\n",
    "                direction = \"positiva\" if row['Correlació'] > 0 else \"negativa\"\n",
    "                print(f\"  - {row['Variable']}: {row['Correlació']:.3f} ({direction})\")\n",
    "        else:\n",
    "            print(\"Cap variable mostra correlació forta amb el target (|r| > 0.3)\")\n",
    "        \n",
    "        # Variables amb baixa correlació amb el target\n",
    "        weak_target_corr = target_corr_df[abs(target_corr_df['Correlació']) < 0.05]\n",
    "        if not weak_target_corr.empty:\n",
    "            print(f\"\\nVariables amb baixa correlació amb el target (|r| < 0.05):\")\n",
    "            for _, row in weak_target_corr.iterrows():\n",
    "                print(f\"  - {row['Variable']}: {row['Correlació']:.3f}\")\n",
    "    \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = implementar_tags_model(DataSet_amb_sinergia, DataSet_herois, combinacions_equips_df, min_partides=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_remove = [f't{team}_champ{i}id' for team in [1, 2] for i in range(1, 6)]\n",
    "cols_to_remove += [f't{team}_champ{champ}_sum{s}' for team in [1, 2] for champ in range(1, 6) for s in [1,2]]\n",
    "cols_to_remove += [f't{team}_ban{champ}' for team in [1, 2] for champ in range(1, 6)]\n",
    "\n",
    "# Verificar quines columnes existeixen\n",
    "existing_cols = [col for col in cols_to_remove if col in data_set.columns]\n",
    "data_set = data_set.drop(columns=existing_cols, errors='ignore')\n",
    "print(f\"Columnes restants: {data_set.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22deae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_matriu_correlacio(data_set, target_attribute='winner', figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2776976",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminació columnes determinades per la primera correlació\n",
    "cols_to_remove = [f't{team}_champ{i}id' for team in [1, 2] for i in range(1, 6)]\n",
    "cols_to_remove += [f't{team}_champ{champ}_sum{s}' for team in [1, 2] for champ in range(1, 6) for s in [1,2]]\n",
    "cols_to_remove += [f't{team}_ban{champ}' for team in [1, 2] for champ in range(1, 6)]\n",
    "\n",
    "\n",
    "# Eliminació de columnes que determinen quins herois de cada equip a acabat amb una estructura\n",
    "cols_to_remove  += ['t1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills',\n",
    "                    't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills']\n",
    "\n",
    "\n",
    "# Verificar quines columnes existeixen\n",
    "existing_cols = [col for col in cols_to_remove if col in data_set.columns]\n",
    "data_set = data_set.drop(columns=existing_cols, errors='ignore')\n",
    "print(f\"Columnes restants: {data_set.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19695641",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_matriu_correlacio(data_set, target_attribute='winner', figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb565a2",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminació columnes determinades per la primera correlació\n",
    "cols_to_remove = [f't{team}_champ{i}id' for team in [1, 2] for i in range(1, 6)]\n",
    "cols_to_remove += [f't{team}_champ{champ}_sum{s}' for team in [1, 2] for champ in range(1, 6) for s in [1,2]]\n",
    "cols_to_remove += [f't{team}_ban{champ}' for team in [1, 2] for champ in range(1, 6)]\n",
    "\n",
    "\n",
    "# Eliminació de columnes que determinen quins herois de cada equip a acabat amb una estructura\n",
    "cols_to_remove  += ['t1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills',\n",
    "                    't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills',\n",
    "                    'firstBlood','firstTower','firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "\n",
    "\n",
    "# Verificar quines columnes existeixen\n",
    "existing_cols = [col for col in cols_to_remove if col in data_set.columns]\n",
    "data_set = data_set.drop(columns=existing_cols, errors='ignore')\n",
    "print(f\"Columnes restants: {data_set.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_matriu_correlacio(data_set, target_attribute='winner', figsize=(12, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
