# League of Legends - AnÃ lisi Predictiu i Data Mining

**Projecte d'Aprenentatge Computacional**  
Universitat de Barcelona - Curs 2024/2025

[English](#english) | [EspaÃ±ol](#espaÃ±ol)

---

## ğŸ“‹ DescripciÃ³ del Projecte

Aquest projecte explora la predicciÃ³ de resultats en partides de League of Legends utilitzant tÃ¨cniques de Machine Learning i Data Mining. MÃ©s enllÃ  de la predicciÃ³ en si, l'objectiu principal Ã©s demostrar la importÃ ncia de la **selecciÃ³ d'atributs** i l'anÃ lisi de dades en el rendiment dels models.

El dataset utilitzat provÃ© de Kaggle i contÃ© informaciÃ³ detallada sobre partides classificatÃ²ries de League of Legends, incloent-hi estadÃ­stiques d'objectius, eliminacions, or acumulat i altres mÃ¨triques de joc.

## ğŸ¯ Objectius

1. **Data Mining**: Identificar quins atributs sÃ³n realment rellevants per la predicciÃ³
2. **AnÃ lisi de CorrelaciÃ³**: Estudiar com la correlaciÃ³ entre variables afecta el rendiment del model
3. **OptimitzaciÃ³ de Features**: Demostrar que menys dades, perÃ² ben seleccionades, poden superar models amb totes les variables
4. **ComparaciÃ³ de Models**: Avaluar diferents algoritmes de classificaciÃ³ sobre el mateix dataset

## ğŸ“‚ Estructura del Repositori

```
â”œâ”€â”€ LOL - Dataset/           # Dataset original de Kaggle
â”œâ”€â”€ AnÃ lisi_de_dades/        # Notebooks d'exploraciÃ³ i visualitzaciÃ³
â”œâ”€â”€ SelecciÃ³ de Model/       # Entrenament i comparaciÃ³ de models
â””â”€â”€ DescripciÃ³ Dades.txt     # DocumentaciÃ³ dels atributs
```

## ğŸ” ProcÃ©s de Data Mining

### 1. ExploraciÃ³ Inicial
El dataset original contÃ© mÃ©s de 60 atributs, incloent-hi:
- EstadÃ­stiques d'objectius (torres, dracs, barons)
- MÃ¨triques individuals (or, eliminacions, assists)
- InformaciÃ³ temporal (duraciÃ³ de partida)
- Esdeveniments clau (primer sang, primera torre)

### 2. AnÃ lisi de CorrelaciÃ³
MitjanÃ§ant matrius de correlaciÃ³, s'identifiquen:
- **Atributs altament correlacionats** amb el resultat (winner)
- **RedundÃ ncia entre variables**: atributs que aporten informaciÃ³ similar
- **Soroll**: variables amb alta desviaciÃ³ estÃ ndard i baixa correlaciÃ³

**Descoberta clau**: Atributs com `towerKills` i objectius d'equip mostren les correlacions mÃ©s fortes, mentre que mÃ¨triques individuals solen ser menys predictives.

### 3. SelecciÃ³ d'Atributs
Del conjunt original de 60+ atributs, es redueix a aproximadament **11-15 features clau**:
- Eliminacions de torres (team1TowerKills, team2TowerKills)
- Objectius majors (dracs, barons, heralds)
- Avantatge d'or acumulat
- Esdeveniments crÃ­tics (firstBlood, firstTower)

**Resultat**: Els models amb features seleccionades aconsegueixen millor precisiÃ³ i generalitzaciÃ³ que models amb tots els atributs.

### 4. ComparaciÃ³ de Models
S'han entrenat i comparat diversos algoritmes:
- Decision Trees
- Random Forest
- Support Vector Machines (SVM)
- RegressiÃ³ LogÃ­stica

## ğŸ“Š Resultats Principals

- La **selecciÃ³ estratÃ¨gica d'atributs** millora tant la precisiÃ³ com l'eficiÃ¨ncia computacional
- Les **torres destruÃ¯des** sÃ³n el millor predictor individual del resultat
- La **correlaciÃ³ entre variables** pot introduir soroll: menys pot ser mÃ©s
- Els models entrenen mÃ©s rÃ pid i generalitzen millor amb features curades

## ğŸ› ï¸ Tecnologies Utilitzades

- **Python 3.x**
- **Pandas** & **NumPy**: manipulaciÃ³ de dades
- **Scikit-learn**: models de ML i mÃ¨triques
- **Matplotlib** & **Seaborn**: visualitzaciÃ³
- **Jupyter Notebook**: entorn de desenvolupament

## ğŸ“ˆ Com Executar el Projecte

1. Clona el repositori:
```bash
git clone https://github.com/NIU1710545/Kaggle-Code.git
cd Kaggle-Code
```

2. InstalÂ·la les dependÃ¨ncies:
```bash
pip install pandas numpy scikit-learn xgboost matplotlib seaborn jupyter
```

3. Obre els notebooks:
```bash
jupyter notebook
```

4. Navega a `AnÃ lisi_de_dades/` per explorar el procÃ©s de data mining

## ğŸ’¡ LliÃ§ons Apreses

- **Qualitat sobre quantitat**: Un conjunt curat d'atributs supera un conjunt complet
- **Context del domini**: Entendre el joc (LoL) ajuda a identificar features rellevants
- **IteraciÃ³**: El data mining Ã©s un procÃ©s iteratiu d'anÃ lisi i refinament
- **GeneralitzaciÃ³**: Models mÃ©s simples amb bones features eviten overfitting

## ğŸ“š ReferÃ¨ncies

- Dataset original: [Kaggle - League of Legends Ranked Games](https://www.kaggle.com/)
- InspiraciÃ³: Diversos notebooks de la comunitat de Kaggle sobre predicciÃ³ en LoL

## ğŸ‘¤ Autor

**Laia Lishuang OrÃºs VÃ¡zquez**  
NIU: 1710545  
Universitat de Barcelona

---

*Aquest projecte ha estat desenvolupat com a part de l'assignatura d'Aprenentatge Computacional. L'objectiu principal Ã©s demostrar la importÃ ncia del data mining i la selecciÃ³ d'atributs en el desenvolupament de models predictius.*

---
---

<a name="english"></a>
# League of Legends - Predictive Analysis and Data Mining

**Computational Learning Project**  
University of Barcelona - Academic Year 2024/2025

[CatalÃ ](#league-of-legends---anÃ lisi-predictiu-i-data-mining) | [EspaÃ±ol](#espaÃ±ol)

---

## ğŸ“‹ Project Description

This project explores outcome prediction in League of Legends matches using Machine Learning and Data Mining techniques. Beyond prediction itself, the main objective is to demonstrate the importance of **feature selection** and data analysis in model performance.

The dataset comes from Kaggle and contains detailed information about ranked League of Legends matches, including objective statistics, kills, accumulated gold, and other game metrics.

## ğŸ¯ Objectives

1. **Data Mining**: Identify which attributes are truly relevant for prediction
2. **Correlation Analysis**: Study how correlation between variables affects model performance
3. **Feature Optimization**: Demonstrate that less data, but well-selected, can outperform models with all variables
4. **Model Comparison**: Evaluate different classification algorithms on the same dataset

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ LOL - Dataset/           # Original Kaggle dataset
â”œâ”€â”€ AnÃ lisi_de_dades/        # Exploration and visualization notebooks
â”œâ”€â”€ SelecciÃ³ de Model/       # Model training and comparison
â””â”€â”€ DescripciÃ³ Dades.txt     # Attribute documentation
```

## ğŸ” Data Mining Process

### 1. Initial Exploration
The original dataset contains over 60 attributes, including:
- Objective statistics (towers, dragons, barons)
- Individual metrics (gold, kills, assists)
- Temporal information (match duration)
- Key events (first blood, first tower)

### 2. Correlation Analysis
Through correlation matrices, we identify:
- **Highly correlated attributes** with the outcome (winner)
- **Redundancy between variables**: attributes that provide similar information
- **Noise**: variables with high standard deviation and low correlation

**Key finding**: Attributes like `towerKills` and team objectives show the strongest correlations, while individual metrics tend to be less predictive.

### 3. Feature Selection
From the original set of 60+ attributes, we reduce to approximately **11-15 key features**:
- Tower kills (team1TowerKills, team2TowerKills)
- Major objectives (dragons, barons, heralds)
- Accumulated gold advantage
- Critical events (firstBlood, firstTower)

**Result**: Models with selected features achieve better accuracy and generalization than models with all attributes.

### 4. Model Comparison
Several algorithms have been trained and compared:
- Decision Trees
- Random Forest
- Support Vector Machines (SVM)
- Logistic Regression

## ğŸ“Š Main Results

- **Strategic feature selection** improves both accuracy and computational efficiency
- **Destroyed towers** are the best individual predictor of the outcome
- **Correlation between variables** can introduce noise: less can be more
- Models train faster and generalize better with curated features

## ğŸ› ï¸ Technologies Used

- **Python 3.x**
- **Pandas** & **NumPy**: data manipulation
- **Scikit-learn**: ML models and metrics
- **Matplotlib** & **Seaborn**: visualization
- **Jupyter Notebook**: development environment

## ğŸ“ˆ How to Run the Project

1. Clone the repository:
```bash
git clone https://github.com/NIU1710545/Kaggle-Code.git
cd Kaggle-Code
```

2. Install dependencies:
```bash
pip install pandas numpy scikit-learn xgboost matplotlib seaborn jupyter
```

3. Open the notebooks:
```bash
jupyter notebook
```

4. Navigate to `AnÃ lisi_de_dades/` to explore the data mining process

## ğŸ’¡ Lessons Learned

- **Quality over quantity**: A curated set of attributes outperforms a complete set
- **Domain context**: Understanding the game (LoL) helps identify relevant features
- **Iteration**: Data mining is an iterative process of analysis and refinement
- **Generalization**: Simpler models with good features avoid overfitting

## ğŸ“š References

- Original dataset: [Kaggle - League of Legends Ranked Games](https://www.kaggle.com/)
- Inspiration: Various Kaggle community notebooks on LoL prediction

## ğŸ‘¤ Author

**Laia Lishuang OrÃºs VÃ¡zquez**  
NIU: 1710545  
University of Barcelona

---

*This project was developed as part of the Computational Learning course. The main objective is to demonstrate the importance of data mining and feature selection in developing predictive models.*

---
---

<a name="espaÃ±ol"></a>
# League of Legends - AnÃ¡lisis Predictivo y Data Mining

**Proyecto de Aprendizaje Computacional**  
Universidad de Barcelona - Curso 2024/2025

[CatalÃ ](#league-of-legends---anÃ lisi-predictiu-i-data-mining) | [English](#english)

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto explora la predicciÃ³n de resultados en partidas de League of Legends utilizando tÃ©cnicas de Machine Learning y Data Mining. MÃ¡s allÃ¡ de la predicciÃ³n en sÃ­, el objetivo principal es demostrar la importancia de la **selecciÃ³n de atributos** y el anÃ¡lisis de datos en el rendimiento de los modelos.

El dataset utilizado proviene de Kaggle y contiene informaciÃ³n detallada sobre partidas clasificatorias de League of Legends, incluyendo estadÃ­sticas de objetivos, eliminaciones, oro acumulado y otras mÃ©tricas de juego.

## ğŸ¯ Objetivos

1. **Data Mining**: Identificar quÃ© atributos son realmente relevantes para la predicciÃ³n
2. **AnÃ¡lisis de CorrelaciÃ³n**: Estudiar cÃ³mo la correlaciÃ³n entre variables afecta el rendimiento del modelo
3. **OptimizaciÃ³n de Features**: Demostrar que menos datos, pero bien seleccionados, pueden superar modelos con todas las variables
4. **ComparaciÃ³n de Modelos**: Evaluar diferentes algoritmos de clasificaciÃ³n sobre el mismo dataset

## ğŸ“‚ Estructura del Repositorio

```
â”œâ”€â”€ LOL - Dataset/           # Dataset original de Kaggle
â”œâ”€â”€ AnÃ lisi_de_dades/        # Notebooks de exploraciÃ³n y visualizaciÃ³n
â”œâ”€â”€ SelecciÃ³ de Model/       # Entrenamiento y comparaciÃ³n de modelos
â””â”€â”€ DescripciÃ³ Dades.txt     # DocumentaciÃ³n de los atributos
```

## ğŸ” Proceso de Data Mining

### 1. ExploraciÃ³n Inicial
El dataset original contiene mÃ¡s de 60 atributos, incluyendo:
- EstadÃ­sticas de objetivos (torres, dragones, barones)
- MÃ©tricas individuales (oro, eliminaciones, asistencias)
- InformaciÃ³n temporal (duraciÃ³n de partida)
- Eventos clave (primera sangre, primera torre)

### 2. AnÃ¡lisis de CorrelaciÃ³n
Mediante matrices de correlaciÃ³n, se identifican:
- **Atributos altamente correlacionados** con el resultado (winner)
- **Redundancia entre variables**: atributos que aportan informaciÃ³n similar
- **Ruido**: variables con alta desviaciÃ³n estÃ¡ndar y baja correlaciÃ³n

**Descubrimiento clave**: Atributos como `towerKills` y objetivos de equipo muestran las correlaciones mÃ¡s fuertes, mientras que mÃ©tricas individuales suelen ser menos predictivas.

### 3. SelecciÃ³n de Atributos
Del conjunto original de 60+ atributos, se reduce a aproximadamente **11-15 features clave**:
- Eliminaciones de torres (team1TowerKills, team2TowerKills)
- Objetivos mayores (dragones, barones, heralds)
- Ventaja de oro acumulado
- Eventos crÃ­ticos (firstBlood, firstTower)

**Resultado**: Los modelos con features seleccionadas consiguen mejor precisiÃ³n y generalizaciÃ³n que modelos con todos los atributos.

### 4. ComparaciÃ³n de Modelos
Se han entrenado y comparado varios algoritmos:
- Decision Trees
- Random Forest
- Support Vector Machines (SVM)
- RegresiÃ³n LogÃ­stica

## ğŸ“Š Resultados Principales

- La **selecciÃ³n estratÃ©gica de atributos** mejora tanto la precisiÃ³n como la eficiencia computacional
- Las **torres destruidas** son el mejor predictor individual del resultado
- La **correlaciÃ³n entre variables** puede introducir ruido: menos puede ser mÃ¡s
- Los modelos entrenan mÃ¡s rÃ¡pido y generalizan mejor con features curadas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.x**
- **Pandas** & **NumPy**: manipulaciÃ³n de datos
- **Scikit-learn**: modelos de ML y mÃ©tricas
- **Matplotlib** & **Seaborn**: visualizaciÃ³n
- **Jupyter Notebook**: entorno de desarrollo

## ğŸ“ˆ CÃ³mo Ejecutar el Proyecto

1. Clona el repositorio:
```bash
git clone https://github.com/NIU1710545/Kaggle-Code.git
cd Kaggle-Code
```

2. Instala las dependencias:
```bash
pip install pandas numpy scikit-learn xgboost matplotlib seaborn jupyter
```

3. Abre los notebooks:
```bash
jupyter notebook
```

4. Navega a `AnÃ lisi_de_dades/` para explorar el proceso de data mining

## ğŸ’¡ Lecciones Aprendidas

- **Calidad sobre cantidad**: Un conjunto curado de atributos supera un conjunto completo
- **Contexto del dominio**: Entender el juego (LoL) ayuda a identificar features relevantes
- **IteraciÃ³n**: El data mining es un proceso iterativo de anÃ¡lisis y refinamiento
- **GeneralizaciÃ³n**: Modelos mÃ¡s simples con buenas features evitan overfitting

## ğŸ“š Referencias

- Dataset original: [Kaggle - League of Legends Ranked Games](https://www.kaggle.com/)
- InspiraciÃ³n: Diversos notebooks de la comunidad de Kaggle sobre predicciÃ³n en LoL

## ğŸ‘¤ Autor

**Laia Lishuang OrÃºs VÃ¡zquez**  
NIU: 1710545  
Universidad de Barcelona

---

*Este proyecto ha sido desarrollado como parte de la asignatura de Aprendizaje Computacional. El objetivo principal es demostrar la importancia del data mining y la selecciÃ³n de atributos en el desarrollo de modelos predictivos.*
